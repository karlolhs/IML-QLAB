{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "175d064d",
   "metadata": {},
   "source": [
    "# Práctica Calificada 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83b5d6f",
   "metadata": {},
   "source": [
    "Pregunta 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "665ab56c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Eduio\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\masked.py:61: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6d07bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset original:\n",
      "   Unnamed: 0  Sales  CompPrice  Income  Advertising  Population  Price  \\\n",
      "0           0   9.50        138      73           11         276    120   \n",
      "1           1  11.22        111      48           16         260     83   \n",
      "2           2  10.06        113      35           10         269     80   \n",
      "3           3   7.40        117     100            4         466     97   \n",
      "4           4   4.15        141      64            3         340    128   \n",
      "\n",
      "  ShelveLoc  Age  Education Urban   US  \n",
      "0       Bad   42         17   Yes  Yes  \n",
      "1      Good   65         10   Yes  Yes  \n",
      "2    Medium   59         12   Yes  Yes  \n",
      "3    Medium   55         14   Yes  Yes  \n",
      "4       Bad   38         13   Yes   No  \n"
     ]
    }
   ],
   "source": [
    "# a) Cargar el dataset y eliminar la primera columna si es un índice innecesario\n",
    "url = 'https://raw.githubusercontent.com/qlabpucp/datasets/main/datasets/carseats.csv'\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "print(\"Dataset original:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50064a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Primera columna eliminada (era un índice)\n",
      "\n",
      "Dimensiones después de limpieza: (400, 11)\n",
      "\n",
      "Información del dataset:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 400 entries, 0 to 399\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   Sales        400 non-null    float64\n",
      " 1   CompPrice    400 non-null    int64  \n",
      " 2   Income       400 non-null    int64  \n",
      " 3   Advertising  400 non-null    int64  \n",
      " 4   Population   400 non-null    int64  \n",
      " 5   Price        400 non-null    int64  \n",
      " 6   ShelveLoc    400 non-null    object \n",
      " 7   Age          400 non-null    int64  \n",
      " 8   Education    400 non-null    int64  \n",
      " 9   Urban        400 non-null    object \n",
      " 10  US           400 non-null    object \n",
      "dtypes: float64(1), int64(7), object(3)\n",
      "memory usage: 34.5+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Verificar si la primera columna es un índice innecesario\n",
    "if df.columns[0] == 'Unnamed: 0' or df.iloc[:, 0].equals(pd.Series(range(len(df)))):\n",
    "    df = df.iloc[:, 1:]\n",
    "    print(\"\\n✓ Primera columna eliminada (era un índice)\")\n",
    "else:\n",
    "    print(\"\\n✓ Primera columna conservada (no es un índice)\")\n",
    "\n",
    "print(f\"\\nDimensiones después de limpieza: {df.shape}\")\n",
    "print(f\"\\nInformación del dataset:\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aaf429c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Variables categóricas identificadas: ['ShelveLoc', 'Urban', 'US']\n",
      "\n",
      "Dimensiones después de encoding: (400, 12)\n",
      "\n",
      "Nuevas columnas creadas:\n",
      "['Sales', 'CompPrice', 'Income', 'Advertising', 'Population', 'Price', 'Age', 'Education', 'ShelveLoc_Good', 'ShelveLoc_Medium', 'Urban_Yes', 'US_Yes']\n",
      "\n",
      "Primeras filas del dataset codificado:\n",
      "   Sales  CompPrice  Income  Advertising  Population  Price  Age  Education  \\\n",
      "0   9.50        138      73           11         276    120   42         17   \n",
      "1  11.22        111      48           16         260     83   65         10   \n",
      "2  10.06        113      35           10         269     80   59         12   \n",
      "3   7.40        117     100            4         466     97   55         14   \n",
      "4   4.15        141      64            3         340    128   38         13   \n",
      "\n",
      "   ShelveLoc_Good  ShelveLoc_Medium  Urban_Yes  US_Yes  \n",
      "0               0                 0          1       1  \n",
      "1               1                 0          1       1  \n",
      "2               0                 1          1       1  \n",
      "3               0                 1          1       1  \n",
      "4               0                 0          1       0  \n"
     ]
    }
   ],
   "source": [
    "# b) Convertir las variables categóricas a variables dummy\n",
    "# Identificar variables categóricas\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "print(f\"\\nVariables categóricas identificadas: {categorical_cols}\")\n",
    "\n",
    "# Convertir variables categóricas a dummy\n",
    "# drop_first=True para evitar multicolinealidad (elimina una categoría de referencia)\n",
    "df_encoded = pd.get_dummies(df, columns=categorical_cols, drop_first=True, dtype=int)\n",
    "\n",
    "print(f\"\\nDimensiones después de encoding: {df_encoded.shape}\")\n",
    "print(f\"\\nNuevas columnas creadas:\")\n",
    "print(df_encoded.columns.tolist())\n",
    "print(f\"\\nPrimeras filas del dataset codificado:\")\n",
    "print(df_encoded.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "144c758c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Variable objetivo (y): Sales\n",
      "  - Dimensiones: (400,)\n",
      "  - Estadísticas:\n",
      "    Media: 7.50\n",
      "    Desviación estándar: 2.82\n",
      "    Mínimo: 0.00\n",
      "    Máximo: 16.27\n",
      "\n",
      "Predictores (X):\n",
      "  - Dimensiones: (400, 11)\n",
      "  - Número de características: 11\n",
      "  - Columnas: ['CompPrice', 'Income', 'Advertising', 'Population', 'Price', 'Age', 'Education', 'ShelveLoc_Good', 'ShelveLoc_Medium', 'Urban_Yes', 'US_Yes']\n"
     ]
    }
   ],
   "source": [
    "# c) Separar predictores (X) y variable objetivo (y)\n",
    "# Variable objetivo\n",
    "y = df_encoded['Sales']\n",
    "\n",
    "# Predictores (todas las columnas excepto Sales)\n",
    "X = df_encoded.drop('Sales', axis=1)\n",
    "\n",
    "print(f\"\\nVariable objetivo (y): Sales\")\n",
    "print(f\"  - Dimensiones: {y.shape}\")\n",
    "print(f\"  - Estadísticas:\")\n",
    "print(f\"    Media: {y.mean():.2f}\")\n",
    "print(f\"    Desviación estándar: {y.std():.2f}\")\n",
    "print(f\"    Mínimo: {y.min():.2f}\")\n",
    "print(f\"    Máximo: {y.max():.2f}\")\n",
    "\n",
    "print(f\"\\nPredictores (X):\")\n",
    "print(f\"  - Dimensiones: {X.shape}\")\n",
    "print(f\"  - Número de características: {X.shape[1]}\")\n",
    "print(f\"  - Columnas: {X.columns.tolist()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7efc7c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Conjunto de entrenamiento:\n",
      "  - X_train: (320, 11)\n",
      "  - y_train: (320,)\n",
      "  - Porcentaje: 80.0%\n",
      "\n",
      "Conjunto de prueba:\n",
      "  - X_test: (80, 11)\n",
      "  - y_test: (80,)\n",
      "  - Porcentaje: 20.0%\n"
     ]
    }
   ],
   "source": [
    "# d) Dividir en conjunto de entrenamiento (80%) y prueba (20%)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=10\n",
    ")\n",
    "\n",
    "print(f\"\\nConjunto de entrenamiento:\")\n",
    "print(f\"  - X_train: {X_train.shape}\")\n",
    "print(f\"  - y_train: {y_train.shape}\")\n",
    "print(f\"  - Porcentaje: {(len(X_train)/len(X))*100:.1f}%\")\n",
    "\n",
    "print(f\"\\nConjunto de prueba:\")\n",
    "print(f\"  - X_test: {X_test.shape}\")\n",
    "print(f\"  - y_test: {y_test.shape}\")\n",
    "print(f\"  - Porcentaje: {(len(X_test)/len(X))*100:.1f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
